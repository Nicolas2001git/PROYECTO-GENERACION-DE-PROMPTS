{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff024e52",
   "metadata": {},
   "source": [
    "# ZenPal ‚Äî Demo simple\n",
    "\n",
    "Bienvenido üëã  \n",
    "Esta notebook muestra, de forma muy f√°cil, c√≥mo **ZenPal**:\n",
    "- Genera mensajes de apoyo (Texto ‚Üí Texto).\n",
    "- Crea im√°genes motivacionales (Texto ‚Üí Imagen).\n",
    "- Calcula el costo en tiempo real seg√∫n el texto generado.\n",
    "- Compara **modelos** con tablas claras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a06cd-e9e9-4763-9e32-e9e43702f678",
   "metadata": {},
   "source": [
    "# ZenPal ‚Äì Acompa√±ante Digital para el Bienestar\n",
    "Demostraci√≥n de Fast Prompting utilizando:\n",
    "- Texto ‚Üí Texto (generaci√≥n de consejos motivacionales)\n",
    "- Texto ‚Üí Imagen (generaci√≥n de recursos visuales con gpt-image-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70866c-bf75-4ba7-803d-2729d04c23ed",
   "metadata": {},
   "source": [
    "üí° Solo necesitas colocar tu **API key** antes de ejecutar las celdas y puedes **editar f√°cilmente** el texto (`usuario_input`) y el prompt (`prompt_imagen`) en las primeras l√≠neas para probar otros casos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2e74a4-e418-4203-bac7-88549e060333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Texto actual para ZenPal: No puedo dormir porque ma√±ana presento un informe importante. ¬øQu√© hago?\n"
     ]
    }
   ],
   "source": [
    "# Importante para el cliente\n",
    "# Cambia el texto de esta variable para probar diferentes situaciones\n",
    "usuario_input = \"No puedo dormir porque ma√±ana presento un informe importante. ¬øQu√© hago?\"\n",
    "print(\"üí° Texto actual para ZenPal:\", usuario_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d8c014c-071c-4f15-92a6-21875031ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\victus\\anaconda3\\lib\\site-packages (1.107.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\victus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\victus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\victus\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4202834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config listo.\n",
      "   - Texto por defecto: gpt-5-mini\n",
      "   - Modelos en tablas: ['gpt-5', 'gpt-5-mini', 'gpt-5-nano']\n",
      "   - Imagen/calidad: gpt-image-1 / image_medium\n",
      "   - USE_API: False | API Key cargada: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuraci√≥n b√°sica (eleg√≠ modelo una sola vez) ---\n",
    "import os, math, random\n",
    "\n",
    "# 1) Tu API Key (opcional). Si no la carg√°s, la demo funciona igual con simulaci√≥n.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")  # o pegala ac√° como string\n",
    "\n",
    "# 2) Activar pruebas reales con la API (True/False)\n",
    "USE_API = False  # Cambi√° a True si quer√©s probar en vivo con tu API Key\n",
    "\n",
    "# 3) Modelos de TEXTO disponibles para comparar\n",
    "#    (Por defecto dejamos la serie GPT-5; 4.1 en la p√°gina es \"optimizaci√≥n\")\n",
    "INCLUDE_GPT41 = False\n",
    "MODELOS_TEXTO = [\"gpt-5\", \"gpt-5-mini\", \"gpt-5-nano\"]\n",
    "if INCLUDE_GPT41:\n",
    "    MODELOS_TEXTO.append(\"gpt-4.1\")  # mostrar√° precios de optimizaci√≥n\n",
    "\n",
    "# 4) Eleg√≠ el modelo por defecto para Texto‚ÜíTexto y c√≥mo comparar en tablas\n",
    "modelo_texto = \"gpt-5-mini\"         # usado en Celda 3 y 7\n",
    "MODELOS_PRUEBA = MODELOS_TEXTO[:]   # usados en Celda 5 y 6\n",
    "\n",
    "# 5) Modelo y calidad para IM√ÅGENES\n",
    "modelo_imagen = \"gpt-image-1\"\n",
    "calidad_img = \"image_medium\"  # opciones: image_low, image_medium, image_high\n",
    "\n",
    "# 6) Precios oficiales (OpenAI pricing) ‚Äî simplificado para inferencia\n",
    "PRICING = {\n",
    "    # Serie GPT-5 (inferencia)\n",
    "    \"gpt-5\": {\n",
    "        \"input_per_1k\": 1.250,\n",
    "        \"input_cache_per_1k\": 0.125,\n",
    "        \"output_per_1k\": 10.000,\n",
    "    },\n",
    "    \"gpt-5-mini\": {\n",
    "        \"input_per_1k\": 0.250,\n",
    "        \"input_cache_per_1k\": 0.025,\n",
    "        \"output_per_1k\": 2.000,\n",
    "    },\n",
    "    \"gpt-5-nano\": {\n",
    "        \"input_per_1k\": 0.050,\n",
    "        \"input_cache_per_1k\": 0.005,\n",
    "        \"output_per_1k\": 0.400,\n",
    "    },\n",
    "\n",
    "    # GPT-4.1 (valores publicados bajo \"optimizaci√≥n\", no inferencia)\n",
    "    \"gpt-4.1\": {\n",
    "        \"input_per_1k\": 3.00,\n",
    "        \"input_cache_per_1k\": 0.75,\n",
    "        \"output_per_1k\": 12.00,\n",
    "    },\n",
    "\n",
    "    # Im√°genes (GPT-image-1)\n",
    "    # Adem√°s de tarifas por tokens, mostramos costo por imagen cuadrada aprox:\n",
    "    \"gpt-image-1\": {\n",
    "        \"input_per_1k\": 5.00,\n",
    "        \"input_cache_per_1k\": 1.25,\n",
    "        \"output_per_1k\": 40.00,\n",
    "        \"image_low\": 0.01,\n",
    "        \"image_medium\": 0.04,\n",
    "        \"image_high\": 0.17\n",
    "    }\n",
    "}\n",
    "\n",
    "# 7) Helpers muy simples\n",
    "def approx_tokens(text: str) -> int:\n",
    "    \"\"\"Aproximaci√≥n r√°pida: ~4 caracteres ‚âà 1 token.\"\"\"\n",
    "    return max(1, math.ceil(len(text)/4))\n",
    "\n",
    "def cost_text(model: str, input_text: str, output_text: str, cached_input: bool=False) -> float:\n",
    "    \"\"\"Calcula el costo para texto con opci√≥n de entrada cacheada.\"\"\"\n",
    "    prices = PRICING[model]\n",
    "    pin = approx_tokens(input_text)\n",
    "    pout = approx_tokens(output_text)\n",
    "    in_key = \"input_cache_per_1k\" if cached_input and \"input_cache_per_1k\" in prices else \"input_per_1k\"\n",
    "    return (pin/1000)*prices[in_key] + (pout/1000)*prices[\"output_per_1k\"]\n",
    "\n",
    "def cost_image(quality_key: str) -> float:\n",
    "    return PRICING[\"gpt-image-1\"][quality_key]\n",
    "\n",
    "# 8) Material de demo sin costo (aleatorio)\n",
    "PROMPTS_RANDOM = [\n",
    "    \"Estoy bloqueado con una tarea y no s√© por d√≥nde empezar.\",\n",
    "    \"Ma√±ana tengo una presentaci√≥n y estoy muy nervioso.\",\n",
    "    \"Tuve un d√≠a pesado y me cuesta concentrarme para estudiar.\",\n",
    "    \"Quiero mejorar mi rutina sin sentirme abrumado.\"\n",
    "]\n",
    "RESPUESTAS_RANDOM = [\n",
    "    \"Hac√© una lista con 3 pasos m√≠nimos y arranc√° por el m√°s simple.\",\n",
    "    \"Pon√© un temporizador de 20 minutos sin distracciones y movete 2 al terminar.\",\n",
    "    \"Respir√° profundo 60 segundos y acomod√° tu espacio antes de retomar.\",\n",
    "    \"Divid√≠ la tarea en bloques chicos y celebr√° cada mini avance.\"\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Config listo.\")\n",
    "print(\"   - Texto por defecto:\", modelo_texto)\n",
    "print(\"   - Modelos en tablas:\", MODELOS_PRUEBA)\n",
    "print(\"   - Imagen/calidad:\", modelo_imagen, \"/\", calidad_img)\n",
    "print(\"   - USE_API:\", USE_API, \"| API Key cargada:\", bool(OPENAI_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9b35d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Prompt elegido: Estoy bloqueado con una tarea y no s√© por d√≥nde empezar.\n",
      "ü§ñ Respuesta simulada: Respir√° profundo 60 segundos y acomod√° tu espacio antes de retomar.\n",
      "üí∞ Costo estimado con gpt-5-mini: USD 0.041500\n",
      "‚ÑπÔ∏è API desactivada (USE_API=False) o falta OPENAI_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Texto‚ÜíTexto (respuesta aleatoria + costo en tiempo real) ---\n",
    "\n",
    "# Fallback suave por si no corriste la Celda 2\n",
    "import math, random\n",
    "if \"PRICING\" not in globals():\n",
    "    PRICING = {\"gpt-5-mini\": {\"input_per_1k\": 0.25, \"output_per_1k\": 2.00}}\n",
    "if \"approx_tokens\" not in globals():\n",
    "    def approx_tokens(text: str) -> int: return max(1, math.ceil(len(text)/4))\n",
    "if \"cost_text\" not in globals():\n",
    "    def cost_text(model: str, input_text: str, output_text: str, cached_input: bool=False) -> float:\n",
    "        p = PRICING.get(model, PRICING[\"gpt-5-mini\"])\n",
    "        pin = approx_tokens(input_text); pout = approx_tokens(output_text)\n",
    "        return (pin/1000)*p.get(\"input_per_1k\",0.25) + (pout/1000)*p.get(\"output_per_1k\",2.0)\n",
    "if \"PROMPTS_RANDOM\" not in globals():\n",
    "    PROMPTS_RANDOM = [\"Necesito concentrarme mejor.\", \"Estoy nervioso por una entrega.\"]\n",
    "if \"RESPUESTAS_RANDOM\" not in globals():\n",
    "    RESPUESTAS_RANDOM = [\"Hac√© una lista breve y arranc√° por lo m√°s simple.\"]\n",
    "if \"modelo_texto\" not in globals():\n",
    "    modelo_texto = \"gpt-5-mini\"\n",
    "\n",
    "system_prompt = \"Sos un asistente emp√°tico que da consejos simples y concretos.\"\n",
    "user_prompt = random.choice(PROMPTS_RANDOM)\n",
    "respuesta_simulada = random.choice(RESPUESTAS_RANDOM)\n",
    "\n",
    "# Costo estimado (sin API) seg√∫n longitud real de input/output\n",
    "estimated_cost = cost_text(modelo_texto, system_prompt + user_prompt, respuesta_simulada)\n",
    "\n",
    "print(\"üìù Prompt elegido:\", user_prompt)\n",
    "print(\"ü§ñ Respuesta simulada:\", respuesta_simulada)\n",
    "print(f\"üí∞ Costo estimado con {modelo_texto}: USD {estimated_cost:.6f}\")\n",
    "\n",
    "# --- Prueba REAL con la API (opcional) ---\n",
    "if 'USE_API' in globals() and USE_API and 'OPENAI_API_KEY' in globals() and OPENAI_API_KEY:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=modelo_texto,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        answer = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "        usage = completion.get(\"usage\", {})\n",
    "        pin = usage.get(\"prompt_tokens\", approx_tokens(system_prompt + user_prompt))\n",
    "        pout = usage.get(\"completion_tokens\", approx_tokens(answer))\n",
    "        prices = PRICING[modelo_texto]\n",
    "        real_cost = (pin/1000)*prices[\"input_per_1k\"] + (pout/1000)*prices[\"output_per_1k\"]\n",
    "\n",
    "        print(\"\\n‚úÖ API (en vivo)\")\n",
    "        print(\"ü§ñ Respuesta:\", answer)\n",
    "        print(f\"üî¢ Tokens ‚Üí input: {pin}, output: {pout}, total: {pin+pout}\")\n",
    "        print(f\"üí∞ Costo real con {modelo_texto}: USD {real_cost:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è No se pudo usar la API (revis√° tu key o librer√≠a). Error:\", e)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è API desactivada (USE_API=False) o falta OPENAI_API_KEY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc08aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Prompt de la imagen: P√≥ster motivacional que diga: 'Descansar tambi√©n es parte del progreso', estilo c√°lido y simple.\n",
      "üí∞ Costo estimado (gpt-image-1 / image_medium): USD 0.04\n",
      "‚ÑπÔ∏è API desactivada (USE_API=False) o falta OPENAI_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Celda 4: Texto‚ÜíImagen (costo por calidad + opci√≥n en vivo) ---\n",
    "\n",
    "# Fallback por si no corriste Celda 2\n",
    "if \"cost_image\" not in globals():\n",
    "    def cost_image(q): return {\"image_low\":0.01,\"image_medium\":0.04,\"image_high\":0.17}[q]\n",
    "if \"calidad_img\" not in globals():\n",
    "    calidad_img = \"image_medium\"\n",
    "if \"modelo_imagen\" not in globals():\n",
    "    modelo_imagen = \"gpt-image-1\"\n",
    "\n",
    "prompt_img = \"P√≥ster motivacional que diga: 'Descansar tambi√©n es parte del progreso', estilo c√°lido y simple.\"\n",
    "costo_img = cost_image(calidad_img)\n",
    "\n",
    "print(\"üñºÔ∏è Prompt de la imagen:\", prompt_img)\n",
    "print(f\"üí∞ Costo estimado ({modelo_imagen} / {calidad_img}): USD {costo_img:.2f}\")\n",
    "\n",
    "# --- Prueba REAL con la API (opcional) ---\n",
    "if 'USE_API' in globals() and USE_API and 'OPENAI_API_KEY' in globals() and OPENAI_API_KEY:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        # Descomentar si quer√©s generar de verdad (puede tener costo):\n",
    "        # resp = openai.Image.create(prompt=prompt_img, n=1, size=\"1024x1024\")\n",
    "        # print(\"üîó URL imagen:\", resp[\"data\"][0][\"url\"])\n",
    "        print(\"‚ÑπÔ∏è Llamada real comentada para evitar costes accidentales. Descoment√° si quer√©s generar.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è No se pudo usar la API de im√°genes. Error:\", e)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è API desactivada (USE_API=False) o falta OPENAI_API_KEY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fdb4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Entrada (USD/1k)</th>\n",
       "      <th>Salida (USD/1k)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-5-mini</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-5-nano</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Modelo  Entrada (USD/1k)  Salida (USD/1k)\n",
       "0       gpt-5              1.25             10.0\n",
       "1  gpt-5-mini              0.25              2.0\n",
       "2  gpt-5-nano              0.05              0.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ---  Precios por modelo (USD / 1k tokens) ---\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for m in MODELOS_PRUEBA:\n",
    "    p = PRICING[m]\n",
    "    rows.append([m, p[\"input_per_1k\"], p[\"output_per_1k\"]])\n",
    "\n",
    "df_precios = pd.DataFrame(rows, columns=[\"Modelo\", \"Entrada (USD/1k)\", \"Salida (USD/1k)\"])\n",
    "df_precios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc77001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Respuesta</th>\n",
       "      <th>Tokens in</th>\n",
       "      <th>Tokens out</th>\n",
       "      <th>Costo (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-5</td>\n",
       "      <td>Tuve un d√≠a pesado y me cuesta concentrarme pa...</td>\n",
       "      <td>Divid√≠ la tarea en bloques chicos y celebr√° ca...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>0.18875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-5-mini</td>\n",
       "      <td>Tuve un d√≠a pesado y me cuesta concentrarme pa...</td>\n",
       "      <td>Divid√≠ la tarea en bloques chicos y celebr√° ca...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>0.03775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-5-nano</td>\n",
       "      <td>Tuve un d√≠a pesado y me cuesta concentrarme pa...</td>\n",
       "      <td>Hac√© una lista con 3 pasos m√≠nimos y arranc√° p...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Modelo                                             Prompt  \\\n",
       "0       gpt-5  Tuve un d√≠a pesado y me cuesta concentrarme pa...   \n",
       "1  gpt-5-mini  Tuve un d√≠a pesado y me cuesta concentrarme pa...   \n",
       "2  gpt-5-nano  Tuve un d√≠a pesado y me cuesta concentrarme pa...   \n",
       "\n",
       "                                           Respuesta  Tokens in  Tokens out  \\\n",
       "0  Divid√≠ la tarea en bloques chicos y celebr√° ca...         23          16   \n",
       "1  Divid√≠ la tarea en bloques chicos y celebr√° ca...         23          16   \n",
       "2  Hac√© una lista con 3 pasos m√≠nimos y arranc√° p...         23          16   \n",
       "\n",
       "   Costo (USD)  \n",
       "0      0.18875  \n",
       "1      0.03775  \n",
       "2      0.00755  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ---‚Äî Mismo prompt en varios modelos ---\n",
    "import pandas as pd, random\n",
    "\n",
    "system_prompt2 = \"Sos un asistente emp√°tico y claro.\"\n",
    "PROMPTS_RANDOM = PROMPTS_RANDOM if \"PROMPTS_RANDOM\" in globals() else [\n",
    "    \"Estoy bloqueado con una tarea y no s√© por d√≥nde empezar.\",\n",
    "    \"Ma√±ana tengo una presentaci√≥n y estoy muy nervioso.\"\n",
    "]\n",
    "RESPUESTAS_RANDOM = RESPUESTAS_RANDOM if \"RESPUESTAS_RANDOM\" in globals() else [\n",
    "    \"Hac√© una lista con 3 pasos m√≠nimos y arranc√° por el m√°s simple.\"\n",
    "]\n",
    "test_prompt = random.choice(PROMPTS_RANDOM)\n",
    "\n",
    "def run_sim(model_name: str, user_text: str):\n",
    "    sim_answer = random.choice(RESPUESTAS_RANDOM)\n",
    "    est_cost = cost_text(model_name, system_prompt2 + user_text, sim_answer)\n",
    "    return sim_answer, approx_tokens(system_prompt2 + user_text), approx_tokens(sim_answer), est_cost\n",
    "\n",
    "def run_live(model_name: str, user_text: str):\n",
    "    try:\n",
    "        import openai\n",
    "        if not OPENAI_API_KEY:\n",
    "            raise RuntimeError(\"Falta OPENAI_API_KEY\")\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt2},\n",
    "                      {\"role\": \"user\", \"content\": user_text}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        answer = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "        usage = completion.get(\"usage\", {})\n",
    "        pin  = usage.get(\"prompt_tokens\",  approx_tokens(system_prompt2 + user_text))\n",
    "        pout = usage.get(\"completion_tokens\", approx_tokens(answer))\n",
    "        prices = PRICING[model_name]\n",
    "        real_cost = (pin/1000)*prices[\"input_per_1k\"] + (pout/1000)*prices[\"output_per_1k\"]\n",
    "        return answer, pin, pout, real_cost\n",
    "    except Exception as e:\n",
    "        return f\"(Error API: {e})\", 0, 0, 0.0\n",
    "\n",
    "rows = []\n",
    "for m in MODELOS_PRUEBA:\n",
    "    if USE_API and OPENAI_API_KEY:\n",
    "        ans, pin, pout, cost = run_live(m, test_prompt)\n",
    "    else:\n",
    "        ans, pin, pout, cost = run_sim(m, test_prompt)\n",
    "    rows.append([m, test_prompt, ans, pin, pout, cost])\n",
    "\n",
    "df_compare = pd.DataFrame(rows, columns=[\"Modelo\", \"Prompt\", \"Respuesta\", \"Tokens in\", \"Tokens out\", \"Costo (USD)\"])\n",
    "df_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5918b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Respuesta</th>\n",
       "      <th>Tokens in</th>\n",
       "      <th>Tokens out</th>\n",
       "      <th>Costo (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estoy bloqueado con una tarea y no s√© por d√≥nd...</td>\n",
       "      <td>Respir√° profundo 60 segundos y acomod√° tu espa...</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0.03975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuve un d√≠a pesado y me cuesta concentrarme pa...</td>\n",
       "      <td>Respir√° profundo 60 segundos y acomod√° tu espa...</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0.03975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estoy bloqueado con una tarea y no s√© por d√≥nd...</td>\n",
       "      <td>Pon√© un temporizador de 20 minutos sin distrac...</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>0.04375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  Estoy bloqueado con una tarea y no s√© por d√≥nd...   \n",
       "1  Tuve un d√≠a pesado y me cuesta concentrarme pa...   \n",
       "2  Estoy bloqueado con una tarea y no s√© por d√≥nd...   \n",
       "\n",
       "                                           Respuesta  Tokens in  Tokens out  \\\n",
       "0  Respir√° profundo 60 segundos y acomod√° tu espa...         23          17   \n",
       "1  Respir√° profundo 60 segundos y acomod√° tu espa...         23          17   \n",
       "2  Pon√© un temporizador de 20 minutos sin distrac...         23          19   \n",
       "\n",
       "   Costo (USD)  \n",
       "0      0.03975  \n",
       "1      0.03975  \n",
       "2      0.04375  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Variantes aleatorias con un modelo ---\n",
    "import pandas as pd, random\n",
    "\n",
    "N = 3  # cantidad de ejecuciones\n",
    "modelo = modelo_texto  # usa el modelo elegido en la Celda 2\n",
    "\n",
    "def run_once(model_name: str):\n",
    "    up = random.choice(PROMPTS_RANDOM)\n",
    "    if USE_API and OPENAI_API_KEY:\n",
    "        # Reutilizamos run_live de la celda anterior\n",
    "        ans, pin, pout, cost = run_live(model_name, up)\n",
    "    else:\n",
    "        ans, pin, pout, cost = run_sim(model_name, up)\n",
    "    return {\"Prompt\": up, \"Respuesta\": ans, \"Tokens in\": pin, \"Tokens out\": pout, \"Costo (USD)\": cost}\n",
    "\n",
    "df_runs = pd.DataFrame([run_once(modelo) for _ in range(N)])\n",
    "df_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447031de-71d7-4431-9412-1f29750976d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Texto actual para ZenPal: No puedo dormir porque ma√±ana presento un informe importante. ¬øQu√© hago?\n",
      "Respuesta del modelo:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Rel√°jate y Prep√°rate para Triunfar\",\n",
      "  \"steps\": [\n",
      "    \"Haz una lista de verificaci√≥n r√°pida de tus puntos clave para el informe, asegur√°ndote de que todo est√© en su lugar.\",\n",
      "    \"Realiza una breve meditaci√≥n guiada o ejercicios de respiraci√≥n para calmar tu mente y cuerpo antes de dormir.\"\n",
      "  ],\n",
      "  \"tone\": \"warm\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os, json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# üîë API key (o setear OPENAI_API_KEY en variables de entorno antes de ejecutar)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"tu_api_va_aqui\")\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# üìù Entrada del usuario (puedes editar esta l√≠nea para probar otras situaciones)\n",
    "usuario_input = \"No puedo dormir porque ma√±ana presento un informe importante. ¬øQu√© hago?\"\n",
    "print(\"üí° Texto actual para ZenPal:\", usuario_input)\n",
    "\n",
    "# üéØ Fast Prompting con creatividad controlada\n",
    "system_rules = \"\"\"\n",
    "Eres ZenPal, un acompa√±ante digital emp√°tico y pr√°ctico.\n",
    "Sigue estas reglas:\n",
    "- Devuelve un JSON con las claves {\"title\": str, \"steps\": [str, str], \"tone\": str}.\n",
    "- \"title\": breve y motivador, 5‚Äì7 palabras.\n",
    "- \"steps\": exactamente dos acciones concretas, claras y realistas.\n",
    "- \"tone\": siempre \"warm\".\n",
    "- S√© amable, directo y motivador.\n",
    "\"\"\"\n",
    "\n",
    "# ‚úÖ Aqu√≠ usamos la variable usuario_input\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_rules},\n",
    "    {\"role\": \"user\", \"content\": usuario_input}  # üëà aqu√≠ usamos la variable\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # o gpt-4o-mini si prefieres m√°s econ√≥mico\n",
    "    messages=messages,\n",
    "    temperature=0.8,  # mayor creatividad = respuestas variadas\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "# Mostrar como Markdown\n",
    "raw = response.choices[0].message.content\n",
    "\n",
    "try:\n",
    "    data = json.loads(raw)\n",
    "    md = f\"### {data['title']}\\n\\n**Paso 1:** {data['steps'][0]}\\n\\n**Paso 2:** {data['steps'][1]}\\n\\n_Tono: {data['tone']}._\"\n",
    "    display(Markdown(md))\n",
    "except:\n",
    "    print(\"Respuesta del modelo:\\n\")\n",
    "    print(raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88468868-edf5-4398-bc5d-1a07706da843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64, os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# üîë API key (o setear OPENAI_API_KEY en variables de entorno antes de ejecutar)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"tu_clave_Api_va_aqui\")\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# üìù Prompt de imagen (edita esta l√≠nea para generar algo distinto)\n",
    "prompt_imagen = \"Minimal breathing guide: a soft circle expanding/contracting in calm blue/green, neutral background, flat style, smooth gradients, no text.\"\n",
    "print(\"üé® Prompt actual:\", prompt_imagen)\n",
    "\n",
    "# Generar imagen\n",
    "result = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt_imagen,\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "# Guardar y mostrar\n",
    "image_base64 = result.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "os.makedirs(\"../assets/images\", exist_ok=True)\n",
    "path = \"../assets/images/breathing_guide.png\"\n",
    "with open(path, \"wb\") as f:\n",
    "    f.write(image_bytes)\n",
    "\n",
    "print(f\"‚úÖ Imagen generada y guardada en {path}\")\n",
    "display(Image(filename=path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9b4eb-8ad9-474c-a871-e3a3e730892e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Nicol√°s Riveira"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "zenpal": {
   "cells": 7,
   "created": "2025-09-02T20:47:58.523495Z",
   "project": "ZenPal - Demo Cliente (Final)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
