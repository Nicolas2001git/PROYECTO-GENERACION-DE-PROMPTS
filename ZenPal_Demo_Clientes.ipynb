{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff024e52",
   "metadata": {},
   "source": [
    "# ZenPal ‚Äî Demo simple\n",
    "\n",
    "Bienvenido üëã  \n",
    "Esta notebook muestra, de forma muy f√°cil, c√≥mo **ZenPal**:\n",
    "- Genera mensajes de apoyo (Texto ‚Üí Texto).\n",
    "- Crea im√°genes motivacionales (Texto ‚Üí Imagen).\n",
    "- Calcula el costo en tiempo real seg√∫n el texto generado.\n",
    "- Compara **modelos** con tablas claras.\n",
    "\n",
    "### C√≥mo usar (4 pasos)\n",
    "1. **Celda 2:** Eleg√≠ los modelos y la calidad de imagen. Si quer√©s probar **en vivo**, peg√° tu `OPENAI_API_KEY` y pon√© `USE_API = True`.\n",
    "2. **Celda 3:** Texto‚ÜíTexto (respuesta aleatoria + costo estimado / real).\n",
    "3. **Celda 4:** Texto‚ÜíImagen (costo por calidad).\n",
    "4. **Celdas 5‚Äì7:** Tablas comparativas (pueden correr en **modo demo** o **real**).\n",
    "\n",
    "> Por defecto, **no usa la API** para evitar gastos. Si activ√°s `USE_API`, se calcula el **costo real** con los tokens que reporta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4202834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config listo.\n",
      "   - Texto por defecto: gpt-5-mini\n",
      "   - Modelos en tablas: ['gpt-5', 'gpt-5-mini', 'gpt-5-nano']\n",
      "   - Imagen/calidad: gpt-image-1 / image_medium\n",
      "   - USE_API: False | API Key cargada: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuraci√≥n b√°sica (eleg√≠ modelo una sola vez) ---\n",
    "import os, math, random\n",
    "\n",
    "# 1) Tu API Key (opcional). Si no la carg√°s, la demo funciona igual con simulaci√≥n.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")  # o pegala ac√° como string\n",
    "\n",
    "# 2) Activar pruebas reales con la API (True/False)\n",
    "USE_API = False  # Cambi√° a True si quer√©s probar en vivo con tu API Key\n",
    "\n",
    "# 3) Modelos de TEXTO disponibles para comparar\n",
    "#    (Por defecto dejamos la serie GPT-5; 4.1 en la p√°gina es \"optimizaci√≥n\")\n",
    "INCLUDE_GPT41 = False\n",
    "MODELOS_TEXTO = [\"gpt-5\", \"gpt-5-mini\", \"gpt-5-nano\"]\n",
    "if INCLUDE_GPT41:\n",
    "    MODELOS_TEXTO.append(\"gpt-4.1\")  # mostrar√° precios de optimizaci√≥n\n",
    "\n",
    "# 4) Eleg√≠ el modelo por defecto para Texto‚ÜíTexto y c√≥mo comparar en tablas\n",
    "modelo_texto = \"gpt-5-mini\"         # usado en Celda 3 y 7\n",
    "MODELOS_PRUEBA = MODELOS_TEXTO[:]   # usados en Celda 5 y 6\n",
    "\n",
    "# 5) Modelo y calidad para IM√ÅGENES\n",
    "modelo_imagen = \"gpt-image-1\"\n",
    "calidad_img = \"image_medium\"  # opciones: image_low, image_medium, image_high\n",
    "\n",
    "# 6) Precios oficiales (OpenAI pricing) ‚Äî simplificado para inferencia\n",
    "PRICING = {\n",
    "    # Serie GPT-5 (inferencia)\n",
    "    \"gpt-5\": {\n",
    "        \"input_per_1k\": 1.250,\n",
    "        \"input_cache_per_1k\": 0.125,\n",
    "        \"output_per_1k\": 10.000,\n",
    "    },\n",
    "    \"gpt-5-mini\": {\n",
    "        \"input_per_1k\": 0.250,\n",
    "        \"input_cache_per_1k\": 0.025,\n",
    "        \"output_per_1k\": 2.000,\n",
    "    },\n",
    "    \"gpt-5-nano\": {\n",
    "        \"input_per_1k\": 0.050,\n",
    "        \"input_cache_per_1k\": 0.005,\n",
    "        \"output_per_1k\": 0.400,\n",
    "    },\n",
    "\n",
    "    # GPT-4.1 (valores publicados bajo \"optimizaci√≥n\", no inferencia)\n",
    "    \"gpt-4.1\": {\n",
    "        \"input_per_1k\": 3.00,\n",
    "        \"input_cache_per_1k\": 0.75,\n",
    "        \"output_per_1k\": 12.00,\n",
    "    },\n",
    "\n",
    "    # Im√°genes (GPT-image-1)\n",
    "    # Adem√°s de tarifas por tokens, mostramos costo por imagen cuadrada aprox:\n",
    "    \"gpt-image-1\": {\n",
    "        \"input_per_1k\": 5.00,\n",
    "        \"input_cache_per_1k\": 1.25,\n",
    "        \"output_per_1k\": 40.00,\n",
    "        \"image_low\": 0.01,\n",
    "        \"image_medium\": 0.04,\n",
    "        \"image_high\": 0.17\n",
    "    }\n",
    "}\n",
    "\n",
    "# 7) Helpers muy simples\n",
    "def approx_tokens(text: str) -> int:\n",
    "    \"\"\"Aproximaci√≥n r√°pida: ~4 caracteres ‚âà 1 token.\"\"\"\n",
    "    return max(1, math.ceil(len(text)/4))\n",
    "\n",
    "def cost_text(model: str, input_text: str, output_text: str, cached_input: bool=False) -> float:\n",
    "    \"\"\"Calcula el costo para texto con opci√≥n de entrada cacheada.\"\"\"\n",
    "    prices = PRICING[model]\n",
    "    pin = approx_tokens(input_text)\n",
    "    pout = approx_tokens(output_text)\n",
    "    in_key = \"input_cache_per_1k\" if cached_input and \"input_cache_per_1k\" in prices else \"input_per_1k\"\n",
    "    return (pin/1000)*prices[in_key] + (pout/1000)*prices[\"output_per_1k\"]\n",
    "\n",
    "def cost_image(quality_key: str) -> float:\n",
    "    return PRICING[\"gpt-image-1\"][quality_key]\n",
    "\n",
    "# 8) Material de demo sin costo (aleatorio)\n",
    "PROMPTS_RANDOM = [\n",
    "    \"Estoy bloqueado con una tarea y no s√© por d√≥nde empezar.\",\n",
    "    \"Ma√±ana tengo una presentaci√≥n y estoy muy nervioso.\",\n",
    "    \"Tuve un d√≠a pesado y me cuesta concentrarme para estudiar.\",\n",
    "    \"Quiero mejorar mi rutina sin sentirme abrumado.\"\n",
    "]\n",
    "RESPUESTAS_RANDOM = [\n",
    "    \"Hac√© una lista con 3 pasos m√≠nimos y arranc√° por el m√°s simple.\",\n",
    "    \"Pon√© un temporizador de 20 minutos sin distracciones y movete 2 al terminar.\",\n",
    "    \"Respir√° profundo 60 segundos y acomod√° tu espacio antes de retomar.\",\n",
    "    \"Divid√≠ la tarea en bloques chicos y celebr√° cada mini avance.\"\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Config listo.\")\n",
    "print(\"   - Texto por defecto:\", modelo_texto)\n",
    "print(\"   - Modelos en tablas:\", MODELOS_PRUEBA)\n",
    "print(\"   - Imagen/calidad:\", modelo_imagen, \"/\", calidad_img)\n",
    "print(\"   - USE_API:\", USE_API, \"| API Key cargada:\", bool(OPENAI_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Texto‚ÜíTexto (respuesta aleatoria + costo en tiempo real) ---\n",
    "\n",
    "# Fallback suave por si no corriste la Celda 2\n",
    "import math, random\n",
    "if \"PRICING\" not in globals():\n",
    "    PRICING = {\"gpt-5-mini\": {\"input_per_1k\": 0.25, \"output_per_1k\": 2.00}}\n",
    "if \"approx_tokens\" not in globals():\n",
    "    def approx_tokens(text: str) -> int: return max(1, math.ceil(len(text)/4))\n",
    "if \"cost_text\" not in globals():\n",
    "    def cost_text(model: str, input_text: str, output_text: str, cached_input: bool=False) -> float:\n",
    "        p = PRICING.get(model, PRICING[\"gpt-5-mini\"])\n",
    "        pin = approx_tokens(input_text); pout = approx_tokens(output_text)\n",
    "        return (pin/1000)*p.get(\"input_per_1k\",0.25) + (pout/1000)*p.get(\"output_per_1k\",2.0)\n",
    "if \"PROMPTS_RANDOM\" not in globals():\n",
    "    PROMPTS_RANDOM = [\"Necesito concentrarme mejor.\", \"Estoy nervioso por una entrega.\"]\n",
    "if \"RESPUESTAS_RANDOM\" not in globals():\n",
    "    RESPUESTAS_RANDOM = [\"Hac√© una lista breve y arranc√° por lo m√°s simple.\"]\n",
    "if \"modelo_texto\" not in globals():\n",
    "    modelo_texto = \"gpt-5-mini\"\n",
    "\n",
    "system_prompt = \"Sos un asistente emp√°tico que da consejos simples y concretos.\"\n",
    "user_prompt = random.choice(PROMPTS_RANDOM)\n",
    "respuesta_simulada = random.choice(RESPUESTAS_RANDOM)\n",
    "\n",
    "# Costo estimado (sin API) seg√∫n longitud real de input/output\n",
    "estimated_cost = cost_text(modelo_texto, system_prompt + user_prompt, respuesta_simulada)\n",
    "\n",
    "print(\"üìù Prompt elegido:\", user_prompt)\n",
    "print(\"ü§ñ Respuesta simulada:\", respuesta_simulada)\n",
    "print(f\"üí∞ Costo estimado con {modelo_texto}: USD {estimated_cost:.6f}\")\n",
    "\n",
    "# --- Prueba REAL con la API (opcional) ---\n",
    "if 'USE_API' in globals() and USE_API and 'OPENAI_API_KEY' in globals() and OPENAI_API_KEY:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=modelo_texto,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        answer = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "        usage = completion.get(\"usage\", {})\n",
    "        pin = usage.get(\"prompt_tokens\", approx_tokens(system_prompt + user_prompt))\n",
    "        pout = usage.get(\"completion_tokens\", approx_tokens(answer))\n",
    "        prices = PRICING[modelo_texto]\n",
    "        real_cost = (pin/1000)*prices[\"input_per_1k\"] + (pout/1000)*prices[\"output_per_1k\"]\n",
    "\n",
    "        print(\"\\n‚úÖ API (en vivo)\")\n",
    "        print(\"ü§ñ Respuesta:\", answer)\n",
    "        print(f\"üî¢ Tokens ‚Üí input: {pin}, output: {pout}, total: {pin+pout}\")\n",
    "        print(f\"üí∞ Costo real con {modelo_texto}: USD {real_cost:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è No se pudo usar la API (revis√° tu key o librer√≠a). Error:\", e)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è API desactivada (USE_API=False) o falta OPENAI_API_KEY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Celda 4: Texto‚ÜíImagen (costo por calidad + opci√≥n en vivo) ---\n",
    "\n",
    "# Fallback por si no corriste Celda 2\n",
    "if \"cost_image\" not in globals():\n",
    "    def cost_image(q): return {\"image_low\":0.01,\"image_medium\":0.04,\"image_high\":0.17}[q]\n",
    "if \"calidad_img\" not in globals():\n",
    "    calidad_img = \"image_medium\"\n",
    "if \"modelo_imagen\" not in globals():\n",
    "    modelo_imagen = \"gpt-image-1\"\n",
    "\n",
    "prompt_img = \"P√≥ster motivacional que diga: 'Descansar tambi√©n es parte del progreso', estilo c√°lido y simple.\"\n",
    "costo_img = cost_image(calidad_img)\n",
    "\n",
    "print(\"üñºÔ∏è Prompt de la imagen:\", prompt_img)\n",
    "print(f\"üí∞ Costo estimado ({modelo_imagen} / {calidad_img}): USD {costo_img:.2f}\")\n",
    "\n",
    "# --- Prueba REAL con la API (opcional) ---\n",
    "if 'USE_API' in globals() and USE_API and 'OPENAI_API_KEY' in globals() and OPENAI_API_KEY:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        # Descomentar si quer√©s generar de verdad (puede tener costo):\n",
    "        # resp = openai.Image.create(prompt=prompt_img, n=1, size=\"1024x1024\")\n",
    "        # print(\"üîó URL imagen:\", resp[\"data\"][0][\"url\"])\n",
    "        print(\"‚ÑπÔ∏è Llamada real comentada para evitar costes accidentales. Descoment√° si quer√©s generar.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è No se pudo usar la API de im√°genes. Error:\", e)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è API desactivada (USE_API=False) o falta OPENAI_API_KEY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---  Precios por modelo (USD / 1k tokens) ---\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for m in MODELOS_PRUEBA:\n",
    "    p = PRICING[m]\n",
    "    rows.append([m, p[\"input_per_1k\"], p[\"output_per_1k\"]])\n",
    "\n",
    "df_precios = pd.DataFrame(rows, columns=[\"Modelo\", \"Entrada (USD/1k)\", \"Salida (USD/1k)\"])\n",
    "df_precios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc77001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---‚Äî Mismo prompt en varios modelos ---\n",
    "import pandas as pd, random\n",
    "\n",
    "system_prompt2 = \"Sos un asistente emp√°tico y claro.\"\n",
    "PROMPTS_RANDOM = PROMPTS_RANDOM if \"PROMPTS_RANDOM\" in globals() else [\n",
    "    \"Estoy bloqueado con una tarea y no s√© por d√≥nde empezar.\",\n",
    "    \"Ma√±ana tengo una presentaci√≥n y estoy muy nervioso.\"\n",
    "]\n",
    "RESPUESTAS_RANDOM = RESPUESTAS_RANDOM if \"RESPUESTAS_RANDOM\" in globals() else [\n",
    "    \"Hac√© una lista con 3 pasos m√≠nimos y arranc√° por el m√°s simple.\"\n",
    "]\n",
    "test_prompt = random.choice(PROMPTS_RANDOM)\n",
    "\n",
    "def run_sim(model_name: str, user_text: str):\n",
    "    sim_answer = random.choice(RESPUESTAS_RANDOM)\n",
    "    est_cost = cost_text(model_name, system_prompt2 + user_text, sim_answer)\n",
    "    return sim_answer, approx_tokens(system_prompt2 + user_text), approx_tokens(sim_answer), est_cost\n",
    "\n",
    "def run_live(model_name: str, user_text: str):\n",
    "    try:\n",
    "        import openai\n",
    "        if not OPENAI_API_KEY:\n",
    "            raise RuntimeError(\"Falta OPENAI_API_KEY\")\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt2},\n",
    "                      {\"role\": \"user\", \"content\": user_text}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        answer = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "        usage = completion.get(\"usage\", {})\n",
    "        pin  = usage.get(\"prompt_tokens\",  approx_tokens(system_prompt2 + user_text))\n",
    "        pout = usage.get(\"completion_tokens\", approx_tokens(answer))\n",
    "        prices = PRICING[model_name]\n",
    "        real_cost = (pin/1000)*prices[\"input_per_1k\"] + (pout/1000)*prices[\"output_per_1k\"]\n",
    "        return answer, pin, pout, real_cost\n",
    "    except Exception as e:\n",
    "        return f\"(Error API: {e})\", 0, 0, 0.0\n",
    "\n",
    "rows = []\n",
    "for m in MODELOS_PRUEBA:\n",
    "    if USE_API and OPENAI_API_KEY:\n",
    "        ans, pin, pout, cost = run_live(m, test_prompt)\n",
    "    else:\n",
    "        ans, pin, pout, cost = run_sim(m, test_prompt)\n",
    "    rows.append([m, test_prompt, ans, pin, pout, cost])\n",
    "\n",
    "df_compare = pd.DataFrame(rows, columns=[\"Modelo\", \"Prompt\", \"Respuesta\", \"Tokens in\", \"Tokens out\", \"Costo (USD)\"])\n",
    "df_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Variantes aleatorias con un modelo ---\n",
    "import pandas as pd, random\n",
    "\n",
    "N = 3  # cantidad de ejecuciones\n",
    "modelo = modelo_texto  # usa el modelo elegido en la Celda 2\n",
    "\n",
    "def run_once(model_name: str):\n",
    "    up = random.choice(PROMPTS_RANDOM)\n",
    "    if USE_API and OPENAI_API_KEY:\n",
    "        # Reutilizamos run_live de la celda anterior\n",
    "        ans, pin, pout, cost = run_live(model_name, up)\n",
    "    else:\n",
    "        ans, pin, pout, cost = run_sim(model_name, up)\n",
    "    return {\"Prompt\": up, \"Respuesta\": ans, \"Tokens in\": pin, \"Tokens out\": pout, \"Costo (USD)\": cost}\n",
    "\n",
    "df_runs = pd.DataFrame([run_once(modelo) for _ in range(N)])\n",
    "df_runs\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Nicol√°s Riveira"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "zenpal": {
   "cells": 7,
   "created": "2025-09-02T20:47:58.523495Z",
   "project": "ZenPal - Demo Cliente (Final)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
